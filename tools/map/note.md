# @tools/map 상세 설계안

네이버 지도 음식점 데이터를 계층적 영역 분할 방식으로 수집하는 고성능 크롤러 모듈입니다.

## 1. 시스템 아키텍처

### 1.1 런타임 및 기술 스택
- **Runtime**: [Bun](https://bun.sh/) (고성능 자바스크립트 런타임)
- **Language**: TypeScript
- **Database**: [bun:sqlite](https://bun.sh/docs/api/sqlite) (내장형 고성능 DB)
- **API**: Naver Place GraphQL API

### 1.2 모듈 구조
- `index.ts`: CLI 엔트리 포인트 및 실행 제어
- `src/pipeline/`: 전체 크롤링 흐름 제어 (재귀적 영역 분할 및 데이터 수집)
- `src/box/`: 지리적 영역(Bounding Box) 생성 및 관리
- `src/graphql/`: 네이버 API 통신 및 재시도 로직
- `src/db/`: SQLite 스키마 정의 및 데이터 영속화
- `src/utils/`: 데이터 변환 및 유틸리티

## 2. 핵심 로직: 계층적 영역 분할 (Recursive Grid Splitting)

네이버 지도 API는 한 번의 검색에 최대 250~300개의 결과만 반환합니다. 이를 극복하기 위해 다음과 같은 전략을 사용합니다.

### 2.1 분할 프로세스
1. 지정된 영역(예: 10km x 10km)의 전체 음식점 개수를 조회합니다.
2. 개수가 **250개 이상**인 경우, 해당 영역을 더 작은 하위 영역으로 분할합니다.
3. 개수가 **250개 미만**이 될 때까지 재귀적으로 반복합니다.
4. 최하단 영역(최소 0.1km)에 도달하거나 250개 미만인 경우 실제 데이터를 수집합니다.

### 2.2 단계별 km 설정 (`getNextKm`)
- **초기(10km) 분할 시**:
  - 1000개 이상 → 1km
  - 500개 이상 → 2km
  - 400개 이상 → 3km
  - 기타 → 5km
- **이후 단계**: `5km → 4km → 3km → 2km → 1km → 0.5km → 0.1km` 순으로 정밀화

## 3. 데이터 모델 (SQLite)

### 3.1 `tbl_place`
음식점의 기본 정보(이름, 주소, 좌표, 카테고리 등)를 저장합니다.

### 3.2 `tbl_place_analysis`
리뷰 통계, 테마, 메뉴별 키워드, 투표 데이터 등 분석용 데이터를 JSON 형태로 저장합니다.

### 3.3 `box_status`
크롤링 진행 상태를 기록하여 중단 시 재시작이 가능하도록 관리합니다.
- `status`: `pending` (대기), `completed` (완료), `empty` (데이터 없음)

## 4. 안정성 및 성능 최적화

- **HTTP 429 대응**: 네이버 API의 속도 제한 발생 시 지수 백오프(Exponential Backoff)를 적용하여 재시도합니다.
- **WAL 모드**: SQLite의 Write-Ahead Logging 모드를 활성화하여 동시성 및 쓰기 성능을 향상시켰습니다.
- **상태 관리**: 파일 기반이 아닌 DB 기반 상태 관리를 통해 대규모 데이터 수집 시의 안정성을 확보했습니다.

## 5. 실행 방법

```bash
# 전국 영역 수집
bun index.ts search

# 대전 영역 수집 (예시)
bun index.ts search daejeon
```

## 6. 데이터 수집 범위 상세

### 6.1 수집 항목 (Included)
*   **음식점 기본 정보 (`tbl_place`)**: 
    *   ID, 이름, 카테고리, 전화번호, 도로명/지번 주소.
    *   좌표(X, Y), 대표 이미지 리스트, 홈페이지 URL.
    *   편의시설(주차, 예약 등), 결제 수단(제로페이 등).
*   **분석 및 통계 (`tbl_place_analysis`)**:
    *   평균 별점, 총 리뷰 수, 방문자 사진 총합.
    *   **테마 키워드**: 네이버 AI가 분류한 특징(예: "분위기 좋은", "가성비").
    *   **인기 메뉴**: 메뉴명, 가격, 추천 여부 정보.
    *   **방문자 투표**: 사용자들이 직접 선택한 키워드별 통계(예: "음식이 맛있어요" - 150명).

### 6.2 미수집 항목 (Excluded)
*   **개별 리뷰 텍스트**: 개별 사용자가 작성한 상세 리뷰 내용 및 작성자 정보.
*   **리뷰 사진 원본**: 리뷰에 첨부된 개별 사진 데이터.
*   **상세 메뉴판 이미지**: 메뉴의 텍스트 정보는 수집하나, 메뉴판 사진 파일 자체는 제외.

### 8.3 실패 항목 기록 및 사후 처리 (Failover Storage)
*   **전용 실패 테이블 (`tbl_crawl_fail`)**: 최대 재시도 횟수를 초과하거나 예기치 못한 에러(429 등)로 수집에 실패한 개별 음식점 ID를 별도로 기록합니다.
*   **배치 처리 (Batch Processing)**: 효율성을 위해 음식점 상세 정보를 10개 단위로 묶어서(Batch) 요청합니다.
*   **기록 항목**: 실패한 음식점 ID, 이름, 실패 사유(Error Message), 해당 영역(Box) 정보 및 km 크기.
*   **전략**: 
    *   배치 요청이 최종적으로 실패(Max retries exceeded)할 경우, 해당 배치에 포함된 모든 항목을 `tbl_crawl_fail`로 보내 사후에 재시도할 수 있도록 합니다.
    *   박스 전체를 포기하지 않고, 실패한 항목만 기록 후 다음 항목으로 진행하여 전체 수집 효율을 극복합니다.
    *   수집 완료 후 `tbl_crawl_fail`에 기록된 ID들만 추출하여 별도의 재시도 프로세스를 실행할 수 있는 기반을 마련합니다.

## 7. 데이터베이스 및 파일 구조

### 7.1 SQLite 파일 위치
*   **기본 경로**: `tools/map/map_data.sqlite`
*   **특징**: 실행 시 자동 생성되며, 단일 파일로 모든 데이터를 관리하여 이식성이 높음.

### 7.2 주요 테이블 설계
*   `tbl_place`: 장소 마스터 데이터. 복잡한 배열형 데이터는 JSON 문자열로 직렬화하여 저장.
*   `tbl_place_analysis`: 통계성 데이터 전용 테이블.
*   `box_status`: 크롤링 진행 상태 관리 테이블.

## 8. Failover 및 재시작 전략

### 8.1 중단 시 재시작 (Checkpoint)
*   **박스 단위 상태 관리**: 수집 영역을 최소 0.1km 단위의 박스로 나누어 관리합니다.
*   **진행 상황 기록**: 각 박스 처리가 완료되면 `box_status` 테이블에 `completed` 상태를 기록합니다.
*   **자동 Resume**: 프로그램 재실행 시 완료된 박스는 즉시 건너뛰고, `pending` 상태이거나 기록이 없는 박스부터 수집을 재개합니다.

### 8.2 API 요청 안정성 (Retry & Backoff)
*   **429 에러 대응**: 네이버 API의 속도 제한 발생 시 즉시 중단하지 않고 대기합니다.
*   **지수 백오프**: 실패 시 대기 시간을 `3초 -> 6초 -> 12초 -> 24초` 순으로 두 배씩 늘려가며 최대 5회 재시도합니다.
*   **데이터 정합성**: `Upsert` 로직을 통해 동일 장소가 중복 발견되어도 데이터를 덮어쓰거나 갱신하여 중복을 방지합니다.